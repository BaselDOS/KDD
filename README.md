# Human Activity Recognition (HAR) â€“ Full KDD Pipeline  
### Machine Learning â€¢ Classification â€¢ Clustering â€¢ PCA â€¢ Sensor Data Analysis

This project presents a complete implementation of the **KDD (Knowledge Discovery in Databases)** methodology applied to the well-known **Human Activity Recognition (UCI-HAR)** dataset.  
The goal is to explore, model, interpret, and extract meaningful insights from high-dimensional motion sensor data collected from smartphone accelerometer and gyroscope measurements.

---

## ğŸ“Œ Project Overview

The project follows **all stages of the KDD process**, including:

1. **Selection & Understanding**  
2. **Preprocessing & Cleaning**  
3. **Transformation & Feature Engineering**  
4. **Supervised Learning (Classification)**  
5. **Unsupervised Learning (Clustering)**  
6. **Evaluation & Interpretation**

Both **classification models** and **clustering models** were built to examine whether the intrinsic structure of the dataset aligns with human activity categories â€” even without supervision.

---

## ğŸ“‚ Dataset

**UCI Human Activity Recognition (HAR)**  
Link: https://www.kaggle.com/datasets/drsaeedmohsen/ucihar-dataset/data

- 30 participants wearing a smartphone on their waist  
- Accelerometer & gyroscope readings  
- Over **560 features extracted**  
- Activities (Target classes):
  - 1 â€“ Walking  
  - 2 â€“ Walking Upstairs  
  - 3 â€“ Walking Downstairs  
  - 4 â€“ Sitting  
  - 5 â€“ Standing  
  - 6 â€“ Laying  

---

## ğŸ§¹ Stage 1â€“3: Preprocessing, Cleaning & Feature Transformation

### âœ” Performed steps:
- Missing values check â†’ **no missing data**
- Duplicate sample check â†’ **no duplicates found**
- Outlier analysis using IQR  
- Standardization of all continuous features  
- Dimensionality reduction using **PCA**
- Selection of **15 dominant features** using feature variance + PCA loadings

### âœ” Visualizations:
- Histograms  
- Boxplots  
- Correlation heatmap  
- PCA explained variance  

---

## ğŸ¤– Stage 4: Supervised Learning (Classification)

Three classification models were trained:

| Model | Accuracy | Precision | Recall | F1 | AUC |
|-------|----------|-----------|--------|----|------|
| **Decision Tree** | Good | Moderate | Moderate | Moderate | - |
| **Random Forest** | Higher | High | High | High | - |
| **SVM** | **Best** | **Highest** | **Highest** | **Highest** | **Highest** |

### âœ” Key Findings
- **SVM** achieved the strongest results across all metrics.  
- The dataset contains clear discriminative structure separating static vs. dynamic activities.  
- Decision Tree interpretability was explored via zoomed-in subtree visualizations.

---

## ğŸ” Stage 5: Unsupervised Learning (K-Means Clustering)

### âœ” Optimal number of clusters: **K = 4**  
(According to the **Elbow Method**)  

### âœ” Visualizations:
- PCA 2D projection of cluster assignments  
- Dominant-feature scatter plots with KDE contours  
- t-SNE projection for improved 2D cluster separation  

### âœ” Cluster Interpretability  
Clusters showed **strong alignment** with true activity labels:

- **Cluster 0:** Sitting & Standing (static)  
- **Cluster 1:** Walking & transitions (dynamic)  
- **Cluster 2:** Walking/Walking Downstairs (dynamic)  
- **Cluster 3:** Almost entirely Laying (very pure cluster)  

---

## ğŸ§  Stage 6: Final Evaluation  
The unsupervised clustering results support the conclusions from classification:

- Both supervised and unsupervised models identified similar structures in the feature space.  
- Static vs. dynamic activities form well-separated groups.  
- K-Means produced **interpretable and meaningful** clusters, confirming that the dataset is highly structured.  

---

## ğŸ“Š Project Structure

